{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f12ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 14:07:36,031 - INFO - Loading combined data for SUBJID mapping...\n",
      "2025-08-25 14:07:36,548 - INFO - Loading airway trees from data/airways_607...\n",
      "2025-08-25 14:08:03,280 - INFO - Initializing EdgeGNN model for feature extraction...\n",
      "2025-08-25 14:08:03,286 - INFO - Loading trained model state dict from models/EdgeGNN_regressor/EdgeGNN_regressor.pth...\n",
      "2025-08-25 14:08:03,305 - INFO - Trained model loaded successfully.\n",
      "2025-08-25 14:08:03,306 - INFO - Starting feature extraction...\n",
      "2025-08-25 14:08:03,824 - INFO - Extracted features saved to models/EdgeGNN_regressor/extracted_features\\extracted_airway_features_32d.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, LeakyReLU, Tanh\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Batch, DataLoader\n",
    "from torch_geometric.nn import EdgeConv, global_mean_pool\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# --- Configure Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Model Parameters (Must match the trained model's parameters) ---\n",
    "# These parameters are taken directly from your provided training script\n",
    "best_lr = 0.001 # Not used for feature extraction, but needed for model initialization\n",
    "best_hidden_channels = 128 # Not directly used in this script, but part of original model context\n",
    "best_embedding_dim = 32 # This is the expected output dimension of the features\n",
    "best_num_conv_layers = 3\n",
    "best_mlp1_layers_dims = [32, 32, 32] # Updated as per your query\n",
    "best_mlp2_layers_dims = [64, 64, 64] # Updated as per your query\n",
    "best_edgeconv_aggr = 'max'\n",
    "best_use_batchnorm = True\n",
    "best_activation_name = 'relu'\n",
    "\n",
    "activation_map = {'relu': ReLU(), 'leaky_relu': LeakyReLU(), 'tanh': Tanh()}\n",
    "best_mlp_activation = activation_map[best_activation_name]\n",
    "\n",
    "\n",
    "# --- Define the Adjusted EdgeGNN Model (same as your training script) ---\n",
    "class AirwayEdgeGNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, output_channels,\n",
    "                 num_conv_layers=3, mlp1_layers=[64, 64], mlp2_layers=[64, 64],\n",
    "                 mlp_activation=ReLU(), edgeconv_aggr='max', use_batchnorm=False):\n",
    "        super(AirwayEdgeGNN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        mlp1 = []\n",
    "        in_channels = 2 * num_node_features\n",
    "        for h_dim in mlp1_layers:\n",
    "            mlp1.append(Linear(in_channels, h_dim))\n",
    "            if use_batchnorm:\n",
    "                mlp1.append(BatchNorm1d(h_dim))\n",
    "            mlp1.append(mlp_activation)\n",
    "            in_channels = h_dim\n",
    "        self.convs.append(EdgeConv(nn=Sequential(*mlp1), aggr=edgeconv_aggr))\n",
    "        last_out_channels = mlp1_layers[-1] if mlp1_layers else 2 * num_node_features\n",
    "\n",
    "        for _ in range(num_conv_layers - 1):\n",
    "            mlp_intermediate = []\n",
    "            in_channels = 2 * last_out_channels\n",
    "            for h_dim in mlp2_layers:\n",
    "                mlp_intermediate.append(Linear(in_channels, h_dim))\n",
    "                if use_batchnorm:\n",
    "                    mlp_intermediate.append(BatchNorm1d(h_dim))\n",
    "                mlp_intermediate.append(mlp_activation)\n",
    "                in_channels = h_dim\n",
    "            self.convs.append(EdgeConv(nn=Sequential(*mlp_intermediate), aggr=edgeconv_aggr))\n",
    "            last_out_channels = mlp2_layers[-1] if mlp2_layers else 2 * last_out_channels\n",
    "\n",
    "        self.out = Linear(last_out_channels, output_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # This forward method is for prediction (regression)\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    def extract_features(self, data):\n",
    "        \"\"\"\n",
    "        Extracts features with the dimension specified by best_embedding_dim.\n",
    "        This assumes best_embedding_dim matches the output of the first convolutional layer.\n",
    "\n",
    "        Args:\n",
    "            data (torch_geometric.data.Data): The graph data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The extracted features.\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        if not self.convs:\n",
    "            raise ValueError(\"Model has no convolutional layers to extract features from.\")\n",
    "\n",
    "        # Extract features after the first convolutional layer,\n",
    "        # which outputs features of dimension best_mlp1_layers_dims[-1] (i.e., best_embedding_dim)\n",
    "        x_after_first_conv = self.convs[0](x, edge_index)\n",
    "        pooled_features = global_mean_pool(x_after_first_conv, batch)\n",
    "\n",
    "        # Optional: Add a check to ensure the extracted dimension matches best_embedding_dim\n",
    "        # This is for verification and can be removed if confident in the architecture.\n",
    "        if pooled_features.shape[1] != best_embedding_dim:\n",
    "            logger.warning(f\"Extracted feature dimension ({pooled_features.shape[1]}) does not match best_embedding_dim ({best_embedding_dim}). \"\n",
    "                           \"Ensure best_mlp1_layers_dims[-1] is set to best_embedding_dim for accurate extraction.\")\n",
    "\n",
    "        return pooled_features\n",
    "\n",
    "\n",
    "# --- Data Loading Functions (same as your training script) ---\n",
    "def load_graph_from_excel(filepath):\n",
    "    nodes_df = pd.read_excel(filepath, sheet_name='Nodes')\n",
    "    edges_df = pd.read_excel(filepath, sheet_name='Edges')\n",
    "    nodes = nodes_df['node_id'].tolist()\n",
    "    edges = list(zip(edges_df['bp0'], edges_df['bp1']))\n",
    "    node_features = torch.tensor(nodes_df[['x', 'y', 'z']].values, dtype=torch.float)\n",
    "    edge_features = torch.tensor(edges_df[['generation', 'length', 'diameter', 'InArea', 'OutArea', 'InPeri', 'OutPeri', 'WT', 'WA', 'Din', 'Dout', 'Cr']].values, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "    return data\n",
    "\n",
    "def load_all_graphs_from_folder(folder_path):\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "    airway_trees = [load_graph_from_excel(os.path.join(folder_path, f)) for f in graph_files]\n",
    "    return airway_trees\n",
    "\n",
    "\n",
    "# --- Main Execution for Feature Extraction ---\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # --- Paths ---\n",
    "    # Path to the trained model from your previous script\n",
    "    OUTPUT_DIR = 'models/EdgeGNN_regressor'\n",
    "    MODEL_SAVE_PATH = f'{OUTPUT_DIR}/EdgeGNN_regressor.pth'\n",
    "    # Folder containing the airway Excel files for feature extraction\n",
    "    GRAPH_FOLDER_FOR_FEATURES = 'data/airways_607'\n",
    "    # Path to the combined data file for SUBJID mapping\n",
    "    COMBINED_DATA_FILE = 'data/data.xlsx'\n",
    "    # Output directory for extracted features\n",
    "    OUTPUT_FEATURES_DIR = f'{OUTPUT_DIR}/extracted_features'\n",
    "    os.makedirs(OUTPUT_FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Loading combined data for SUBJID mapping...\")\n",
    "    try:\n",
    "        combined_df = pd.read_excel(COMBINED_DATA_FILE)\n",
    "        # Filter out rows with 'NONE' in SUBJID, as done in your training script\n",
    "        combined_df = combined_df[combined_df['SUBJID'] != 'NONE']\n",
    "        filename_to_subj_id = {row['Filename']: row['SUBJID'] for _, row in combined_df.iterrows()}\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Combined data file not found at {COMBINED_DATA_FILE}. Exiting.\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading combined data file: {e}. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    logger.info(f\"Loading airway trees from {GRAPH_FOLDER_FOR_FEATURES}...\")\n",
    "    airway_trees_raw = load_all_graphs_from_folder(GRAPH_FOLDER_FOR_FEATURES)\n",
    "    graph_filenames = [f for f in os.listdir(GRAPH_FOLDER_FOR_FEATURES) if f.endswith('.xlsx')]\n",
    "    graph_filenames.sort() # Ensure filenames are sorted for consistent processing\n",
    "\n",
    "    # Determine num_node_features from the first loaded graph\n",
    "    if not airway_trees_raw:\n",
    "        logger.error(f\"No airway trees found in {GRAPH_FOLDER_FOR_FEATURES}. Exiting.\")\n",
    "        exit()\n",
    "    num_node_features = airway_trees_raw[0].x.shape[1]\n",
    "    output_dim_placeholder = 1 # This value doesn't matter for feature extraction, but needed for model init\n",
    "\n",
    "    # --- Initialize and Load the Trained GNN Model ---\n",
    "    logger.info(\"Initializing EdgeGNN model for feature extraction...\")\n",
    "    model_feature_extractor = AirwayEdgeGNN(\n",
    "        num_node_features=num_node_features,\n",
    "        output_channels=output_dim_placeholder, # Placeholder, as we're not using the final output layer\n",
    "        num_conv_layers=best_num_conv_layers,\n",
    "        mlp1_layers=best_mlp1_layers_dims,\n",
    "        mlp2_layers=best_mlp2_layers_dims,\n",
    "        mlp_activation=best_mlp_activation,\n",
    "        edgeconv_aggr=best_edgeconv_aggr,\n",
    "        use_batchnorm=best_use_batchnorm\n",
    "    ).to(device)\n",
    "\n",
    "    logger.info(f\"Loading trained model state dict from {MODEL_SAVE_PATH}...\")\n",
    "    try:\n",
    "        model_feature_extractor.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device), strict=False)\n",
    "        model_feature_extractor.eval() # Set model to evaluation mode\n",
    "        logger.info(\"Trained model loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Trained model not found at {MODEL_SAVE_PATH}. Please ensure the model is trained and saved. Exiting.\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading trained model: {e}. Please check the model file and architecture. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # --- Feature Extraction ---\n",
    "    logger.info(\"Starting feature extraction...\")\n",
    "    extracted_data_list = []\n",
    "\n",
    "    # The desired feature dimension is now directly taken from best_embedding_dim\n",
    "    # This assumes best_embedding_dim matches the output of the first conv layer (mlp1_layers_dims[-1])\n",
    "    DESIRED_FEATURE_DIMENSION = best_embedding_dim\n",
    "\n",
    "    for i, file_name in enumerate(graph_filenames):\n",
    "        if file_name in filename_to_subj_id:\n",
    "            graph_data = airway_trees_raw[i]\n",
    "            subj_id = filename_to_subj_id[file_name]\n",
    "\n",
    "            # Prepare data for model\n",
    "            data_to_process = Data(x=graph_data.x, edge_index=graph_data.edge_index, edge_attr=graph_data.edge_attr)\n",
    "            data_to_process = data_to_process.to(device)\n",
    "\n",
    "            # Extract features using the new method (no target_dimension argument needed)\n",
    "            with torch.no_grad():\n",
    "                features = model_feature_extractor.extract_features(data_to_process)\n",
    "\n",
    "            # Convert features to numpy and flatten\n",
    "            features_np = features.cpu().numpy().flatten()\n",
    "\n",
    "            # Create a dictionary for the current row\n",
    "            row_data = {'Filename': file_name, 'SUBJID': subj_id}\n",
    "            for j, feature_val in enumerate(features_np):\n",
    "                row_data[f'EdgeGNN_{j}'] = feature_val\n",
    "            extracted_data_list.append(row_data)\n",
    "        else:\n",
    "            logger.warning(f\"SUBJID for file {file_name} not found in {COMBINED_DATA_FILE}. Skipping feature extraction for this file.\")\n",
    "\n",
    "    # --- Save Extracted Features to CSV ---\n",
    "    if extracted_data_list:\n",
    "        extracted_features_df = pd.DataFrame(extracted_data_list)\n",
    "        # Append the desired dimension to the filename for clarity\n",
    "        csv_filename = f'extracted_airway_features_{DESIRED_FEATURE_DIMENSION}d.csv'\n",
    "        extracted_features_csv_path = os.path.join(OUTPUT_FEATURES_DIR, csv_filename)\n",
    "        extracted_features_df.to_csv(extracted_features_csv_path, index=False)\n",
    "        logger.info(f\"Extracted features saved to {extracted_features_csv_path}\")\n",
    "    else:\n",
    "        logger.warning(\"No features were extracted. Check data paths and file mappings.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
